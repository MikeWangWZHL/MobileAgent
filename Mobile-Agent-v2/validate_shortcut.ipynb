{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MobileAgentE.controller import *\n",
    "\n",
    "ADB_PATH = \"/Users/wangz3/Desktop/vlm_agent_project/platform-tools/adb\"\n",
    "clear_background_and_back_to_home(ADB_PATH)\n",
    "clear_notes(ADB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Tap_Type_and_Enter\n",
      "\targuments: ['x', 'y', 'text']\n",
      "\tdescription: Tap an input box at position (x, y), Type the \"text\", and then perform the Enter operation (useful for searching or sending messages).\n",
      "\taction sequence: [{'name': 'Tap', 'arguments_map': {'x': 'x', 'y': 'y'}}, {'name': 'Type', 'arguments_map': {'text': 'text'}}, {'name': 'Enter', 'arguments_map': {}}]\n",
      "=====================================\n",
      "name: Open_App_And_Create_Note\n",
      "\targuments: ['app_name', 'add_button_x', 'add_button_y', 'input_area_x', 'input_area_y', 'text']\n",
      "\tdescription: Open the specified app, tap the button to create a new note, and type the provided text into the note.\n",
      "\taction sequence: [{'name': 'Open_App', 'arguments_map': {'app_name': 'app_name'}}, {'name': 'Tap', 'arguments_map': {'x': 'add_button_x', 'y': 'add_button_y'}}, {'name': 'Tap', 'arguments_map': {'x': 'input_area_x', 'y': 'input_area_y'}}, {'name': 'Type', 'arguments_map': {'text': 'text'}}]\n",
      "=====================================\n",
      "name: Open_App_And_Add_Note\n",
      "\targuments: ['app_name', 'add_button_x', 'add_button_y']\n",
      "\tdescription: Open the specified app and tap the button to create a new note.\n",
      "\taction sequence: [{'name': 'Open_App', 'arguments_map': {'app_name': 'app_name'}}, {'name': 'Tap', 'arguments_map': {'x': 'add_button_x', 'y': 'add_button_y'}}]\n",
      "=====================================\n",
      "name: Open_App_And_Create_Note_With_Text\n",
      "\targuments: ['app_name', 'add_button_x', 'add_button_y', 'input_area_x', 'input_area_y', 'text']\n",
      "\tdescription: Open the specified app, tap the button to create a new note, and type the provided text into the note.\n",
      "\taction sequence: [{'name': 'Open_App', 'arguments_map': {'app_name': 'app_name'}}, {'name': 'Tap', 'arguments_map': {'x': 'add_button_x', 'y': 'add_button_y'}}, {'name': 'Tap', 'arguments_map': {'x': 'input_area_x', 'y': 'input_area_y'}}, {'name': 'Type', 'arguments_map': {'text': 'text'}}]\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "from MobileAgentE.agents import *\n",
    "import json\n",
    "\n",
    "shortcut_json_path = \"log/agent_E/information_research_example_0_future_task_visible/persistent_shortcuts.json\"\n",
    "shortcuts = json.load(open(shortcut_json_path))\n",
    "\n",
    "for key, item in shortcuts.items():\n",
    "    print(\"name:\", item[\"name\"])\n",
    "    print(\"\\targuments:\", item[\"arguments\"])\n",
    "    print(\"\\tdescription:\", item[\"description\"])\n",
    "    print(\"\\taction sequence:\", item[\"atomic_action_sequence\"])\n",
    "    print(\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /Users/wangz3/.cache/modelscope/hub/AI-ModelScope/GroundingDINO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:22:50,103 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "2024-12-07 10:22:50,744 - modelscope - WARNING - ('PIPELINES', 'grounding-dino-task', 'Groundingdino-generation-pipe') not found in ast index file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: /Users/wangz3/.cache/modelscope/hub/AI-ModelScope/GroundingDINO/bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:22:51,961 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-12-07 10:22:51,962 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-12-07 10:22:51,962 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/Users/wangz3/.cache/modelscope/hub/AI-ModelScope/GroundingDINO'}. trying to build by task and model information.\n",
      "2024-12-07 10:22:51,962 - modelscope - WARNING - No preprocessor key ('Groundingdino', 'grounding-dino-task') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-12-07 10:22:51,964 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /Users/wangz3/.cache/modelscope/hub/iic/cv_resnet18_ocr-detection-db-line-level_damo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:22:53,904 - modelscope - WARNING - Model revision not specified, use revision: v1.3.0\n",
      "2024-12-07 10:22:54,403 - modelscope - INFO - initiate model from /Users/wangz3/.cache/modelscope/hub/iic/cv_resnet18_ocr-detection-db-line-level_damo\n",
      "2024-12-07 10:22:54,403 - modelscope - INFO - initiate model from location /Users/wangz3/.cache/modelscope/hub/iic/cv_resnet18_ocr-detection-db-line-level_damo.\n",
      "2024-12-07 10:22:54,405 - modelscope - INFO - initialize model from /Users/wangz3/.cache/modelscope/hub/iic/cv_resnet18_ocr-detection-db-line-level_damo\n",
      "2024-12-07 10:22:54,578 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2024-12-07 10:22:54,579 - modelscope - INFO - loading model from dir /Users/wangz3/.cache/modelscope/hub/iic/cv_resnet18_ocr-detection-db-line-level_damo\n",
      "2024-12-07 10:22:54,581 - modelscope - INFO - loading model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /Users/wangz3/.cache/modelscope/hub/iic/cv_convnextTiny_ocr-recognition-document_damo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:22:57,887 - modelscope - WARNING - Model revision not specified, use revision: v2.4.0\n",
      "2024-12-07 10:22:58,353 - modelscope - INFO - initiate model from /Users/wangz3/.cache/modelscope/hub/iic/cv_convnextTiny_ocr-recognition-document_damo\n",
      "2024-12-07 10:22:58,354 - modelscope - INFO - initiate model from location /Users/wangz3/.cache/modelscope/hub/iic/cv_convnextTiny_ocr-recognition-document_damo.\n",
      "2024-12-07 10:22:58,356 - modelscope - INFO - initialize model from /Users/wangz3/.cache/modelscope/hub/iic/cv_convnextTiny_ocr-recognition-document_damo\n",
      "2024-12-07 10:22:58,469 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2024-12-07 10:22:58,470 - modelscope - INFO - loading model from dir /Users/wangz3/.cache/modelscope/hub/iic/cv_convnextTiny_ocr-recognition-document_damo\n",
      "2024-12-07 10:22:58,473 - modelscope - INFO - loading model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loaded perception models:\n",
      "\t- Caption model method: api | caption vlm model: qwen-vl-plus\n",
      "\t- Grounding DINO model: <GroundingDINO.ms_wrapper.GroundingdinoGenerationPipeline object at 0x1719f8880>\n",
      "\t- OCR detection model: iic/cv_resnet18_ocr-detection-db-line-level_damo\n",
      "\t- OCR recognition model: iic/cv_convnextTiny_ocr-recognition-document_damo\n"
     ]
    }
   ],
   "source": [
    "from run_agent_E import Perceptor\n",
    "perceptor = Perceptor(ADB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:26:00,614 - modelscope - WARNING - task grounding-dino-task input definition is missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'III', 'c', 'Instagram', 'Lemon8', 'REDnote', 'X', '小红书', 'lemon8', 'Amazon Shopping', 'Fandango', 'Best Buy', 'Walmart', 'R', 'Tripadvisor', 'Booking.com', 'Maps', 'Gmail', 'Booking', 'YouTube', 'TikTok', 'Google', 'Chrome', 'Calendar', 'Notes', 'Contacts', 'Settings', '31', '10:25'] 29\n",
      "['10:25', '31', 'Notes', 'Settings', 'Contacts', 'Calendar', 'Chrome', 'YouTube', 'Google', 'TikTok', 'Booking', 'Booking.com', 'Maps', 'Gmail', 'Tripadvisor', 'R', 'Best Buy', 'Amazon Shopping', 'Fandango', 'Walmart', '小红书', 'lemon8', 'REDnote', 'X', 'Instagram', 'Lemon8', 'c', 'III', 'O'] 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "SupervisionWarnings: annotate is deprecated: `BoxAnnotator` is deprecated and will be removed in `supervision-0.22.0`. Use `BoundingBoxAnnotator` and `LabelAnnotator` instead\n",
      "2024-12-07 10:26:03,103 - modelscope - WARNING - task grounding-dino-task output keys are missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shortcut:  Open_App_And_Create_Note_With_Text\n",
      "\t Executing sub-step 0: Open_App {'app_name': 'Notes'} ...\n",
      "\t Executing sub-step 1: Tap {'x': 933, 'y': 2067} ...\n",
      "\t Executing sub-step 2: Tap {'x': 100, 'y': 520} ...\n",
      "\t Executing sub-step 3: Type {'text': 'Hello, this is a test note.'} ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Open_App_And_Create_Note_With_Text',\n",
       " 'arguments': {'app_name': 'Notes',\n",
       "  'add_button_x': 933,\n",
       "  'add_button_y': 2067,\n",
       "  'input_area_x': 100,\n",
       "  'input_area_y': 520,\n",
       "  'text': 'Hello, this is a test note.'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MobileAgentE.agents import *\n",
    "from MobileAgentE.controller import *\n",
    "import shutil\n",
    "\n",
    "info_pool = InfoPool(\n",
    "    shortcuts=shortcuts,\n",
    ")\n",
    "executor = Executor(ADB_PATH)\n",
    "clear_background_and_back_to_home(ADB_PATH)\n",
    "action_str= \"\"\"{\n",
    "    \"name\": \"Open_App_And_Create_Note_With_Text\",\n",
    "    \"arguments\": {\n",
    "        \"app_name\": \"Notes\",\n",
    "        \"add_button_x\": 933,\n",
    "        \"add_button_y\": 2067,\n",
    "        \"input_area_x\": 100,\n",
    "        \"input_area_y\": 520,\n",
    "        \"text\": \"Hello, this is a test note.\"\n",
    "    }\n",
    "}\"\"\"\n",
    "TEMP_DIR = \"./temp\"\n",
    "screenshot_file = \"./screenshot/screenshot.jpg\"\n",
    "perception_infos, width, height = perceptor.get_perception_infos(screenshot_file, temp_file=TEMP_DIR)\n",
    "shutil.rmtree(TEMP_DIR)\n",
    "os.mkdir(TEMP_DIR)\n",
    "executor.execute(action_str, info_pool, screenshot_file=screenshot_file, \n",
    "                        ocr_detection=perceptor.ocr_detection,\n",
    "                        ocr_recognition=perceptor.ocr_recognition,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
